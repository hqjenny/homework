{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tf_util\n",
    "import gym\n",
    "import load_policy\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_expert_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.loads(f.read())\n",
    "        o = data['observations']\n",
    "        a = data['actions']\n",
    "    return (o, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate 10 rollouts of expert data \n",
    "tasks = ['Hopper-v2', 'Ant-v2', 'HalfCheetah-v2', 'Humanoid-v2', 'Reacher-v2', 'Walker2d-v2']\n",
    "num_rollouts = 10\n",
    "for task in tasks: \n",
    "    filename='experts/'+ task +'.pkl';\n",
    "    from subprocess import call\n",
    "    call([\"python\", \"run_expert.py\", filename, task, \"--num_rollouts=\"+str(num_rollouts)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n",
      "(10000, 1, 3)\n",
      "(10000, 111)\n",
      "(10000, 1, 8)\n",
      "(10000, 17)\n",
      "(10000, 1, 6)\n",
      "(10000, 376)\n",
      "(10000, 1, 17)\n",
      "(500, 11)\n",
      "(500, 1, 2)\n",
      "(10000, 17)\n",
      "(10000, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "for task in tasks: \n",
    "    filename='expert_data/'+ task +'.pkl';\n",
    "    o, a = load_expert_data(filename)\n",
    "    print(o.shape)\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(o, a):\n",
    "    # create inputs\n",
    "    input_ph = tf.placeholder(dtype=tf.float32, shape=[None, o.shape[1]])\n",
    "    output_ph = tf.placeholder(dtype=tf.float32, shape=[None, a.shape[1]])\n",
    "\n",
    "    dim = 256\n",
    "    # create variables\n",
    "    W0 = tf.get_variable(name='W0', shape=[o.shape[1], dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    W1 = tf.get_variable(name='W1', shape=[dim, dim], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    W2 = tf.get_variable(name='W2', shape=[dim, a.shape[1]], initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "    b0 = tf.get_variable(name='b0', shape=[dim], initializer=tf.constant_initializer(0.))\n",
    "    b1 = tf.get_variable(name='b1', shape=[dim], initializer=tf.constant_initializer(0.))\n",
    "    b2 = tf.get_variable(name='b2', shape=[a.shape[1]], initializer=tf.constant_initializer(0.))\n",
    "\n",
    "    weights = [W0, W1, W2]\n",
    "    biases = [b0, b1, b2]\n",
    "    activations = [tf.nn.relu, tf.nn.relu, None]\n",
    "    # create computation graph\n",
    "    layer = input_ph\n",
    "    for W, b, activation in zip(weights, biases, activations):\n",
    "        layer = tf.matmul(layer, W) + b\n",
    "        if activation is not None:\n",
    "            layer = activation(layer)\n",
    "    output_pred = layer\n",
    "\n",
    "    return input_ph, output_ph, output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_run(model, num_rollouts, task, expert_policy=False, max_steps = 1000000):\n",
    "    render = False\n",
    "    import gym\n",
    "    env = gym.make(task)\n",
    "    max_steps = max_steps or env.spec.timestep_limit\n",
    "\n",
    "    returns = []\n",
    "    observations = []\n",
    "    actions = []\n",
    "    for i in range(num_rollouts):\n",
    "        #print('test_run rollout', i)\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        totalr = 0.\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            action = model(obs[None,:])\n",
    "\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            totalr += r\n",
    "            steps += 1\n",
    "            if render:\n",
    "                env.render()\n",
    "            #if steps % 100 == 0: print(\"%i/%i\"%(steps, max_steps))\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "        returns.append(totalr)\n",
    "\n",
    "    print('returns', returns)\n",
    "    print('mean return', np.mean(returns))\n",
    "    print('std of return %lf'%np.std(returns))\n",
    "\n",
    "    data = {'observations': np.array(observations),\n",
    "                   'actions': np.array(actions),\n",
    "                   'returns' : returns\n",
    "                   }\n",
    "    #return (np.mean(returns), np.std(returns))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_reset():\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "    tf.reset_default_graph()\n",
    "    return tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC model \n",
    "def train_model(task, epochs):\n",
    "    filename='expert_data/'+ task +'.pkl';\n",
    "    print(\"Training for {}.\".format(filename))\n",
    "    o, a = load_expert_data(filename)\n",
    "    a = a.reshape(a.shape[0], -1)\n",
    "    train_ratio = 1.0\n",
    "    valid_ratio = 0\n",
    "    test_ratio = 0 \n",
    "    train_index = int( train_ratio* o.shape[0])\n",
    "    valid_index = int( valid_ratio* o.shape[0]) + train_index\n",
    "\n",
    "    indices = np.random.permutation(o.shape[0])\n",
    "    train_indices, valid_indices, test_indices = indices[:train_index], indices[train_index:valid_index], indices[valid_index:]\n",
    "    o_train, o_valid, o_test = o[train_indices], o[valid_indices], o[test_indices]\n",
    "    a_train, a_valid, a_test = a[train_indices], a[valid_indices], a[test_indices]\n",
    "    print(o_train.shape)\n",
    "    print(o_valid.shape)\n",
    "    print(o_test.shape)\n",
    "    model_name = task +'ckpt'\n",
    "    \n",
    "    tf_reset()\n",
    "    with tf.Session() as sess:\n",
    "        input_ph, output_ph, output_pred = create_model(o_train, a_train)\n",
    "\n",
    "        try:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, \"/tmp/1\"+model_name)\n",
    "        except ValueError:\n",
    "            # create loss\n",
    "            mse = tf.reduce_mean(0.5 * tf.square(output_pred - output_ph))\n",
    "\n",
    "            # create optimizer\n",
    "            opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "\n",
    "            # initialize variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # create saver to save model variables\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            # run training\n",
    "            batch_size = 64\n",
    "            iterations = o_train.shape[0] // batch_size\n",
    "            # run BC training\n",
    "            for epoch_step in range(epochs):\n",
    "                for training_step in range(iterations):\n",
    "                    #print(\"training step %d\" % training_step)\n",
    "                    # get a random subset of the training data\n",
    "                    indices = np.random.randint(low=0, high=o_train.shape[0], size=batch_size)\n",
    "                    input_batch = o_train[indices]\n",
    "                    output_batch = a_train[indices]\n",
    "\n",
    "                    # run the optimizer and get the mse\n",
    "                    _, mse_run = sess.run([opt, mse], feed_dict={input_ph: input_batch, output_ph: output_batch})\n",
    "\n",
    "                # print the mse every so often\n",
    "                print('epochs {0:02d} mse: {1:.3f}'.format(epoch_step, mse_run))\n",
    "            saver.save(sess, '/tmp/'+model_name)\n",
    "    \n",
    "    #tf_reset()    \n",
    "        my_model = tf_util.function([input_ph], output_pred)\n",
    "        model_data = test_run(my_model, num_rollouts, task, expert_policy=False)\n",
    "\n",
    "    tf_reset()\n",
    "    with tf.Session() as sess:\n",
    "        policy_fn = load_policy.load_policy('experts/'+task+'.pkl')\n",
    "        ref_data = test_run(policy_fn, num_rollouts, task, expert_policy=True)\n",
    "\n",
    "    model_mean, model_std = (np.mean(model_data['returns']), np.std(model_data['returns']))\n",
    "    ref_mean, ref_std =  (np.mean(ref_data['returns']), np.std(ref_data['returns']))\n",
    "    print(model_mean, ref_mean)\n",
    "    print(model_std, ref_std)\n",
    "    return (model_mean, ref_mean), (model_std, ref_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for expert_data/Hopper-v2.pkl.\n",
      "(10000, 11)\n",
      "(0, 11)\n",
      "(0, 11)\n",
      "epochs 00 mse: 0.013\n",
      "epochs 01 mse: 0.011\n",
      "epochs 02 mse: 0.008\n",
      "epochs 03 mse: 0.009\n",
      "epochs 04 mse: 0.005\n",
      "epochs 05 mse: 0.005\n",
      "epochs 06 mse: 0.005\n",
      "epochs 07 mse: 0.004\n",
      "epochs 08 mse: 0.003\n",
      "epochs 09 mse: 0.003\n",
      "epochs 10 mse: 0.002\n",
      "epochs 11 mse: 0.003\n",
      "epochs 12 mse: 0.003\n",
      "epochs 13 mse: 0.002\n",
      "epochs 14 mse: 0.001\n",
      "epochs 15 mse: 0.002\n",
      "epochs 16 mse: 0.002\n",
      "epochs 17 mse: 0.001\n",
      "epochs 18 mse: 0.001\n",
      "epochs 19 mse: 0.001\n",
      "epochs 20 mse: 0.001\n",
      "epochs 21 mse: 0.001\n",
      "epochs 22 mse: 0.001\n",
      "epochs 23 mse: 0.004\n",
      "epochs 24 mse: 0.001\n",
      "epochs 25 mse: 0.001\n",
      "epochs 26 mse: 0.001\n",
      "epochs 27 mse: 0.001\n",
      "epochs 28 mse: 0.001\n",
      "epochs 29 mse: 0.001\n",
      "epochs 30 mse: 0.001\n",
      "epochs 31 mse: 0.002\n",
      "epochs 32 mse: 0.001\n",
      "epochs 33 mse: 0.001\n",
      "epochs 34 mse: 0.001\n",
      "epochs 35 mse: 0.001\n",
      "epochs 36 mse: 0.003\n",
      "epochs 37 mse: 0.001\n",
      "epochs 38 mse: 0.001\n",
      "epochs 39 mse: 0.001\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [1335.57389580805, 1215.6368477923982, 1367.919863223943, 1214.6153750662445, 1389.5267740781821, 1205.516943280755, 2394.7777390688866, 1555.6133265918256, 1398.6818010093884, 2489.3405206379357]\n",
      "mean return 1556.7203086557608\n",
      "std of return 454.567998\n",
      "obs (1, 11) (1, 11)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [3780.6588008263466, 3779.8061008015493, 3787.98058511326, 3773.6940886094794, 3782.8536262425278, 3776.0294044628395, 3784.5567519880046, 3777.80676049246, 3776.8154557785456, 3770.1877212657323]\n",
      "mean return 3779.0389295580744\n",
      "std of return 5.005942\n",
      "1556.7203086557608 3779.0389295580744\n",
      "454.56799828006626 5.0059419136297745\n",
      "Training for expert_data/Ant-v2.pkl.\n",
      "(10000, 111)\n",
      "(0, 111)\n",
      "(0, 111)\n",
      "epochs 00 mse: 0.006\n",
      "epochs 01 mse: 0.005\n",
      "epochs 02 mse: 0.004\n",
      "epochs 03 mse: 0.002\n",
      "epochs 04 mse: 0.002\n",
      "epochs 05 mse: 0.002\n",
      "epochs 06 mse: 0.002\n",
      "epochs 07 mse: 0.001\n",
      "epochs 08 mse: 0.001\n",
      "epochs 09 mse: 0.002\n",
      "epochs 10 mse: 0.001\n",
      "epochs 11 mse: 0.001\n",
      "epochs 12 mse: 0.001\n",
      "epochs 13 mse: 0.001\n",
      "epochs 14 mse: 0.001\n",
      "epochs 15 mse: 0.001\n",
      "epochs 16 mse: 0.001\n",
      "epochs 17 mse: 0.001\n",
      "epochs 18 mse: 0.001\n",
      "epochs 19 mse: 0.001\n",
      "epochs 20 mse: 0.000\n",
      "epochs 21 mse: 0.000\n",
      "epochs 22 mse: 0.001\n",
      "epochs 23 mse: 0.001\n",
      "epochs 24 mse: 0.000\n",
      "epochs 25 mse: 0.001\n",
      "epochs 26 mse: 0.001\n",
      "epochs 27 mse: 0.001\n",
      "epochs 28 mse: 0.001\n",
      "epochs 29 mse: 0.000\n",
      "epochs 30 mse: 0.000\n",
      "epochs 31 mse: 0.000\n",
      "epochs 32 mse: 0.000\n",
      "epochs 33 mse: 0.000\n",
      "epochs 34 mse: 0.000\n",
      "epochs 35 mse: 0.001\n",
      "epochs 36 mse: 0.000\n",
      "epochs 37 mse: 0.000\n",
      "epochs 38 mse: 0.000\n",
      "epochs 39 mse: 0.000\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4706.1560821899275, 4734.515977239684, 4716.853673674128, 4525.520309575812, 1446.4159334966926, 4420.315510564033, 4671.665735800517, 4786.245518216975, 4655.08772838046, 4589.078959163862]\n",
      "mean return 4325.185542830209\n",
      "std of return 965.074717\n",
      "obs (1, 111) (1, 111)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4987.005765069939, 4925.43409221118, 5007.979236792815, 4881.174436441019, 4777.018536453499, 4858.369677768115, 4903.17581091005, 4650.7451265992695, 4782.653505447335, 4922.145746736092]\n",
      "mean return 4869.570193442931\n",
      "std of return 102.091781\n",
      "4325.185542830209 4869.570193442931\n",
      "965.0747166153727 102.09178127013766\n",
      "Training for expert_data/HalfCheetah-v2.pkl.\n",
      "(10000, 17)\n",
      "(0, 17)\n",
      "(0, 17)\n",
      "epochs 00 mse: 0.028\n",
      "epochs 01 mse: 0.014\n",
      "epochs 02 mse: 0.015\n",
      "epochs 03 mse: 0.007\n",
      "epochs 04 mse: 0.009\n",
      "epochs 05 mse: 0.008\n",
      "epochs 06 mse: 0.007\n",
      "epochs 07 mse: 0.006\n",
      "epochs 08 mse: 0.006\n",
      "epochs 09 mse: 0.005\n",
      "epochs 10 mse: 0.006\n",
      "epochs 11 mse: 0.004\n",
      "epochs 12 mse: 0.004\n",
      "epochs 13 mse: 0.004\n",
      "epochs 14 mse: 0.004\n",
      "epochs 15 mse: 0.005\n",
      "epochs 16 mse: 0.004\n",
      "epochs 17 mse: 0.003\n",
      "epochs 18 mse: 0.003\n",
      "epochs 19 mse: 0.002\n",
      "epochs 20 mse: 0.002\n",
      "epochs 21 mse: 0.002\n",
      "epochs 22 mse: 0.003\n",
      "epochs 23 mse: 0.002\n",
      "epochs 24 mse: 0.002\n",
      "epochs 25 mse: 0.002\n",
      "epochs 26 mse: 0.002\n",
      "epochs 27 mse: 0.003\n",
      "epochs 28 mse: 0.002\n",
      "epochs 29 mse: 0.001\n",
      "epochs 30 mse: 0.004\n",
      "epochs 31 mse: 0.002\n",
      "epochs 32 mse: 0.002\n",
      "epochs 33 mse: 0.002\n",
      "epochs 34 mse: 0.002\n",
      "epochs 35 mse: 0.001\n",
      "epochs 36 mse: 0.001\n",
      "epochs 37 mse: 0.001\n",
      "epochs 38 mse: 0.001\n",
      "epochs 39 mse: 0.002\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [3986.326409201535, 4097.38171559613, 3974.416548064312, 4001.4696077197073, 4009.6276982674403, 4073.4244008798296, 4021.3579607864685, 3974.6998991934847, 3901.046537874647, 3952.467578187233]\n",
      "mean return 3999.221835577079\n",
      "std of return 53.807058\n",
      "obs (1, 17) (1, 17)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4031.55454757941, 4026.8999968871644, 4087.0935445206205, 4176.133396135427, 4130.694557717031, 4107.851347987053, 4055.4810751531436, 4050.5322771589144, 4288.27439693018, 4158.916595960857]\n",
      "mean return 4111.34317360298\n",
      "std of return 76.847764\n",
      "3999.221835577079 4111.34317360298\n",
      "53.80705769424792 76.8477642932673\n",
      "Training for expert_data/Humanoid-v2.pkl.\n",
      "(10000, 376)\n",
      "(0, 376)\n",
      "(0, 376)\n",
      "epochs 00 mse: 1.116\n",
      "epochs 01 mse: 1.004\n",
      "epochs 02 mse: 0.576\n",
      "epochs 03 mse: 0.420\n",
      "epochs 04 mse: 0.805\n",
      "epochs 05 mse: 0.935\n",
      "epochs 06 mse: 0.428\n",
      "epochs 07 mse: 0.388\n",
      "epochs 08 mse: 0.248\n",
      "epochs 09 mse: 0.339\n",
      "epochs 10 mse: 0.176\n",
      "epochs 11 mse: 0.143\n",
      "epochs 12 mse: 0.089\n",
      "epochs 13 mse: 0.152\n",
      "epochs 14 mse: 0.140\n",
      "epochs 15 mse: 0.135\n",
      "epochs 16 mse: 0.141\n",
      "epochs 17 mse: 0.545\n",
      "epochs 18 mse: 0.539\n",
      "epochs 19 mse: 0.102\n",
      "epochs 20 mse: 0.256\n",
      "epochs 21 mse: 0.075\n",
      "epochs 22 mse: 0.077\n",
      "epochs 23 mse: 0.091\n",
      "epochs 24 mse: 0.113\n",
      "epochs 25 mse: 0.109\n",
      "epochs 26 mse: 0.102\n",
      "epochs 27 mse: 0.089\n",
      "epochs 28 mse: 0.093\n",
      "epochs 29 mse: 0.098\n",
      "epochs 30 mse: 0.053\n",
      "epochs 31 mse: 0.052\n",
      "epochs 32 mse: 0.041\n",
      "epochs 33 mse: 0.048\n",
      "epochs 34 mse: 0.058\n",
      "epochs 35 mse: 0.097\n",
      "epochs 36 mse: 0.077\n",
      "epochs 37 mse: 0.046\n",
      "epochs 38 mse: 0.046\n",
      "epochs 39 mse: 0.040\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [542.2155073982427, 326.54058993863464, 323.2343582290852, 331.9251619909449, 414.6803533161109, 605.9549149575438, 443.4598617801212, 300.5015232577331, 423.0843178506823, 496.43320157548004]\n",
      "mean return 420.80297902945784\n",
      "std of return 98.017824\n",
      "obs (1, 376) (1, 376)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [10416.886115844169, 10237.075324943416, 10433.905924188166, 10398.466018687244, 10253.56198090298, 10457.816491818521, 10448.492120289678, 10371.326753468438, 10463.678886965696, 10398.059132715563]\n",
      "mean return 10387.926874982388\n",
      "std of return 76.513529\n",
      "420.80297902945784 10387.926874982388\n",
      "98.01782376584599 76.51352856751735\n",
      "Training for expert_data/Reacher-v2.pkl.\n",
      "(500, 11)\n",
      "(0, 11)\n",
      "(0, 11)\n",
      "epochs 00 mse: 0.014\n",
      "epochs 01 mse: 0.006\n",
      "epochs 02 mse: 0.004\n",
      "epochs 03 mse: 0.002\n",
      "epochs 04 mse: 0.001\n",
      "epochs 05 mse: 0.001\n",
      "epochs 06 mse: 0.001\n",
      "epochs 07 mse: 0.000\n",
      "epochs 08 mse: 0.001\n",
      "epochs 09 mse: 0.001\n",
      "epochs 10 mse: 0.000\n",
      "epochs 11 mse: 0.000\n",
      "epochs 12 mse: 0.001\n",
      "epochs 13 mse: 0.000\n",
      "epochs 14 mse: 0.000\n",
      "epochs 15 mse: 0.000\n",
      "epochs 16 mse: 0.000\n",
      "epochs 17 mse: 0.000\n",
      "epochs 18 mse: 0.000\n",
      "epochs 19 mse: 0.000\n",
      "epochs 20 mse: 0.000\n",
      "epochs 21 mse: 0.000\n",
      "epochs 22 mse: 0.000\n",
      "epochs 23 mse: 0.000\n",
      "epochs 24 mse: 0.000\n",
      "epochs 25 mse: 0.000\n",
      "epochs 26 mse: 0.000\n",
      "epochs 27 mse: 0.000\n",
      "epochs 28 mse: 0.000\n",
      "epochs 29 mse: 0.000\n",
      "epochs 30 mse: 0.000\n",
      "epochs 31 mse: 0.000\n",
      "epochs 32 mse: 0.000\n",
      "epochs 33 mse: 0.000\n",
      "epochs 34 mse: 0.000\n",
      "epochs 35 mse: 0.000\n",
      "epochs 36 mse: 0.000\n",
      "epochs 37 mse: 0.000\n",
      "epochs 38 mse: 0.000\n",
      "epochs 39 mse: 0.000\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [-10.946409557035382, -5.282000524623595, -12.20343032005979, -8.456812953193868, -14.058257008987027, -11.056258116781272, -2.4424069065591025, -10.198356718246586, -8.251425788450726, -2.5577494830826812]\n",
      "mean return -8.545310737702005\n",
      "std of return 3.773815\n",
      "obs (1, 11) (1, 11)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [-2.089198766682266, -3.0878679773725106, -6.960504938872615, -1.9896484566315529, -3.388528443942807, -0.8019063275915302, -3.9890046623043816, -2.8835821691030517, -5.889275754724236, -6.812807937988533]\n",
      "mean return -3.789232543521348\n",
      "std of return 2.004357\n",
      "-8.545310737702005 -3.789232543521348\n",
      "3.773815409919344 2.0043572894876114\n",
      "Training for expert_data/Walker2d-v2.pkl.\n",
      "(10000, 17)\n",
      "(0, 17)\n",
      "(0, 17)\n",
      "epochs 00 mse: 0.047\n",
      "epochs 01 mse: 0.033\n",
      "epochs 02 mse: 0.050\n",
      "epochs 03 mse: 0.019\n",
      "epochs 04 mse: 0.022\n",
      "epochs 05 mse: 0.018\n",
      "epochs 06 mse: 0.014\n",
      "epochs 07 mse: 0.013\n",
      "epochs 08 mse: 0.009\n",
      "epochs 09 mse: 0.010\n",
      "epochs 10 mse: 0.011\n",
      "epochs 11 mse: 0.012\n",
      "epochs 12 mse: 0.006\n",
      "epochs 13 mse: 0.010\n",
      "epochs 14 mse: 0.006\n",
      "epochs 15 mse: 0.007\n",
      "epochs 16 mse: 0.006\n",
      "epochs 17 mse: 0.006\n",
      "epochs 18 mse: 0.005\n",
      "epochs 19 mse: 0.006\n",
      "epochs 20 mse: 0.007\n",
      "epochs 21 mse: 0.005\n",
      "epochs 22 mse: 0.005\n",
      "epochs 23 mse: 0.005\n",
      "epochs 24 mse: 0.005\n",
      "epochs 25 mse: 0.004\n",
      "epochs 26 mse: 0.004\n",
      "epochs 27 mse: 0.004\n",
      "epochs 28 mse: 0.004\n",
      "epochs 29 mse: 0.004\n",
      "epochs 30 mse: 0.004\n",
      "epochs 31 mse: 0.003\n",
      "epochs 32 mse: 0.004\n",
      "epochs 33 mse: 0.004\n",
      "epochs 34 mse: 0.004\n",
      "epochs 35 mse: 0.003\n",
      "epochs 36 mse: 0.003\n",
      "epochs 37 mse: 0.002\n",
      "epochs 38 mse: 0.003\n",
      "epochs 39 mse: 0.004\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [5030.1770029699655, 1551.4391543035695, 4068.5469839415478, 5127.481258782288, 3843.4430581350175, 2951.3346807324338, 3181.0337321757825, 4479.073419431535, 2143.2730225122828, 5192.470231294704]\n",
      "mean return 3756.8272544279125\n",
      "std of return 1209.757998\n",
      "obs (1, 17) (1, 17)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [5484.153524947173, 5462.993875335029, 5551.318896998126, 5475.042821127411, 5519.461248133143, 5580.019684540053, 5471.152940214181, 5568.048475750989, 5527.495631664329, 5571.39843629668]\n",
      "mean return 5521.108553500711\n",
      "std of return 43.034554\n",
      "3756.8272544279125 5521.108553500711\n",
      "1209.7579983998055 43.03455374593591\n",
      "{'Hopper-v2': ((1556.7203086557608, 3779.0389295580744), (454.56799828006626, 5.0059419136297745)), 'Ant-v2': ((4325.185542830209, 4869.570193442931), (965.0747166153727, 102.09178127013766)), 'HalfCheetah-v2': ((3999.221835577079, 4111.34317360298), (53.80705769424792, 76.8477642932673)), 'Humanoid-v2': ((420.80297902945784, 10387.926874982388), (98.01782376584599, 76.51352856751735)), 'Reacher-v2': ((-8.545310737702005, -3.789232543521348), (3.773815409919344, 2.0043572894876114)), 'Walker2d-v2': ((3756.8272544279125, 5521.108553500711), (1209.7579983998055, 43.03455374593591))}\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "part2_2 = {}\n",
    "tasks = ['Hopper-v2', 'Ant-v2', 'HalfCheetah-v2', 'Humanoid-v2', 'Reacher-v2', 'Walker2d-v2']\n",
    "\n",
    "#tasks = ['Hopper-v2']\n",
    "for task in tasks:\n",
    "    part2_2[task] = train_model(task, epochs)\n",
    "print(part2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for expert_data/Ant-v2.pkl.\n",
      "(10000, 111)\n",
      "(0, 111)\n",
      "(0, 111)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [711.3824598011809, 718.9046009092385, 746.742281156787, 726.3766555102812, 729.9742719099019, 718.5548785507559, 726.7625092633199, 725.7642710657879, 719.4632596811784, 711.6608383722125]\n",
      "mean return 723.5586026220644\n",
      "std of return 9.772406\n",
      "obs (1, 111) (1, 111)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4888.016516462192, 4849.817260052209, 4959.560749815952, 4693.764393468458, 4962.949313868536, 4918.521931472284, 4741.640239288129, 4765.001094812556, 4834.152431173692, 4810.127672157263]\n",
      "mean return 4842.355160257128\n",
      "std of return 86.910516\n",
      "723.5586026220644 4842.355160257128\n",
      "9.772406276912639 86.9105160526305\n",
      "Training for expert_data/Ant-v2.pkl.\n",
      "(10000, 111)\n",
      "(0, 111)\n",
      "(0, 111)\n",
      "epochs 00 mse: 0.005\n",
      "epochs 01 mse: 0.004\n",
      "epochs 02 mse: 0.003\n",
      "epochs 03 mse: 0.003\n",
      "epochs 04 mse: 0.002\n",
      "epochs 05 mse: 0.002\n",
      "epochs 06 mse: 0.002\n",
      "epochs 07 mse: 0.002\n",
      "epochs 08 mse: 0.001\n",
      "epochs 09 mse: 0.001\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [3904.5028314025, 4139.274073680945, 4455.775628817967, 2767.266583049635, 1528.9427758342297, 87.21454577380881, 1426.6975095149674, 4453.763708327223, 4318.828342939939, 4509.931375065643]\n",
      "mean return 3159.2197374406855\n",
      "std of return 1526.179810\n",
      "obs (1, 111) (1, 111)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4786.8918324630395, 4868.689769432195, 4784.568358045243, 4905.587065027188, 4820.374424191324, 4595.509092104086, 4766.557093760239, 4767.810298568058, 4500.588448955668, 4894.024108033575]\n",
      "mean return 4769.060049058062\n",
      "std of return 122.302138\n",
      "3159.2197374406855 4769.060049058062\n",
      "1526.1798100087249 122.30213813827991\n",
      "Training for expert_data/Ant-v2.pkl.\n",
      "(10000, 111)\n",
      "(0, 111)\n",
      "(0, 111)\n",
      "epochs 00 mse: 0.006\n",
      "epochs 01 mse: 0.003\n",
      "epochs 02 mse: 0.003\n",
      "epochs 03 mse: 0.003\n",
      "epochs 04 mse: 0.002\n",
      "epochs 05 mse: 0.001\n",
      "epochs 06 mse: 0.001\n",
      "epochs 07 mse: 0.001\n",
      "epochs 08 mse: 0.002\n",
      "epochs 09 mse: 0.001\n",
      "epochs 10 mse: 0.001\n",
      "epochs 11 mse: 0.001\n",
      "epochs 12 mse: 0.001\n",
      "epochs 13 mse: 0.001\n",
      "epochs 14 mse: 0.001\n",
      "epochs 15 mse: 0.001\n",
      "epochs 16 mse: 0.001\n",
      "epochs 17 mse: 0.000\n",
      "epochs 18 mse: 0.001\n",
      "epochs 19 mse: 0.000\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4624.726601768511, 4835.082486205137, 4678.513085757895, 5063.245053860764, 4755.3336931998465, 81.15614650492601, 4922.984075545733, 4794.574061675813, 4717.215288633468, 4779.578791362503]\n",
      "mean return 4325.24092845146\n",
      "std of return 1419.646226\n",
      "obs (1, 111) (1, 111)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4715.741642064375, 4586.901258904276, 4870.980607493172, 4870.94377679727, 5091.659294516588, 4865.939714910878, 4805.323557578052, 4960.257157195362, 4765.996117822779, 4991.034999254349]\n",
      "mean return 4852.47781265371\n",
      "std of return 137.046388\n",
      "4325.24092845146 4852.47781265371\n",
      "1419.6462257893002 137.04638775140003\n",
      "Training for expert_data/Ant-v2.pkl.\n",
      "(10000, 111)\n",
      "(0, 111)\n",
      "(0, 111)\n",
      "epochs 00 mse: 0.005\n",
      "epochs 01 mse: 0.004\n",
      "epochs 02 mse: 0.003\n",
      "epochs 03 mse: 0.002\n",
      "epochs 04 mse: 0.002\n",
      "epochs 05 mse: 0.002\n",
      "epochs 06 mse: 0.002\n",
      "epochs 07 mse: 0.001\n",
      "epochs 08 mse: 0.001\n",
      "epochs 09 mse: 0.001\n",
      "epochs 10 mse: 0.001\n",
      "epochs 11 mse: 0.001\n",
      "epochs 12 mse: 0.001\n",
      "epochs 13 mse: 0.001\n",
      "epochs 14 mse: 0.001\n",
      "epochs 15 mse: 0.001\n",
      "epochs 16 mse: 0.001\n",
      "epochs 17 mse: 0.001\n",
      "epochs 18 mse: 0.001\n",
      "epochs 19 mse: 0.001\n",
      "epochs 20 mse: 0.000\n",
      "epochs 21 mse: 0.001\n",
      "epochs 22 mse: 0.001\n",
      "epochs 23 mse: 0.000\n",
      "epochs 24 mse: 0.001\n",
      "epochs 25 mse: 0.000\n",
      "epochs 26 mse: 0.000\n",
      "epochs 27 mse: 0.000\n",
      "epochs 28 mse: 0.001\n",
      "epochs 29 mse: 0.000\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4791.217158968377, 4668.198900458452, 4837.789563873321, 4748.438146776896, 4725.986562608215, 4882.02234360978, 4671.573403352712, 4367.642945983068, 4736.522649079242, 4596.609738846727]\n",
      "mean return 4702.600141355679\n",
      "std of return 137.002430\n",
      "obs (1, 111) (1, 111)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4901.400943557219, 4838.339847127511, 4752.6452455339, 4843.629920732699, 4923.048390334154, 4874.1818639364965, 5003.524293744917, 4850.332095851894, 4961.955061711101, 4652.195581260753]\n",
      "mean return 4860.125324379065\n",
      "std of return 96.136618\n",
      "4702.600141355679 4860.125324379065\n",
      "137.0024300534319 96.13661799735199\n",
      "Training for expert_data/Ant-v2.pkl.\n",
      "(10000, 111)\n",
      "(0, 111)\n",
      "(0, 111)\n",
      "epochs 00 mse: 0.006\n",
      "epochs 01 mse: 0.004\n",
      "epochs 02 mse: 0.004\n",
      "epochs 03 mse: 0.002\n",
      "epochs 04 mse: 0.002\n",
      "epochs 05 mse: 0.002\n",
      "epochs 06 mse: 0.001\n",
      "epochs 07 mse: 0.002\n",
      "epochs 08 mse: 0.001\n",
      "epochs 09 mse: 0.001\n",
      "epochs 10 mse: 0.001\n",
      "epochs 11 mse: 0.001\n",
      "epochs 12 mse: 0.001\n",
      "epochs 13 mse: 0.001\n",
      "epochs 14 mse: 0.001\n",
      "epochs 15 mse: 0.001\n",
      "epochs 16 mse: 0.001\n",
      "epochs 17 mse: 0.001\n",
      "epochs 18 mse: 0.001\n",
      "epochs 19 mse: 0.001\n",
      "epochs 20 mse: 0.000\n",
      "epochs 21 mse: 0.001\n",
      "epochs 22 mse: 0.000\n",
      "epochs 23 mse: 0.000\n",
      "epochs 24 mse: 0.001\n",
      "epochs 25 mse: 0.000\n",
      "epochs 26 mse: 0.000\n",
      "epochs 27 mse: 0.000\n",
      "epochs 28 mse: 0.001\n",
      "epochs 29 mse: 0.000\n",
      "epochs 30 mse: 0.000\n",
      "epochs 31 mse: 0.000\n",
      "epochs 32 mse: 0.000\n",
      "epochs 33 mse: 0.000\n",
      "epochs 34 mse: 0.000\n",
      "epochs 35 mse: 0.000\n",
      "epochs 36 mse: 0.000\n",
      "epochs 37 mse: 0.000\n",
      "epochs 38 mse: 0.000\n",
      "epochs 39 mse: 0.000\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4486.862552363791, 4673.776295154369, 4781.178454156303, 4782.913289857333, 4734.380083790385, 4733.12447278218, 4750.759658537565, 4653.071189381848, 4753.231771617189, 4772.664901695967]\n",
      "mean return 4712.196266933692\n",
      "std of return 85.594513\n",
      "obs (1, 111) (1, 111)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4674.329309372569, 4865.622922793386, 4684.629229504218, 4665.27223823319, 4901.492172195233, 4790.775542702567, 4708.199753511576, 4659.56538719971, 4823.557734672731, 4851.112554640475]\n",
      "mean return 4762.455684482566\n",
      "std of return 88.976455\n",
      "4712.196266933692 4762.455684482566\n",
      "85.59451300819913 88.97645539091135\n",
      "Training for expert_data/Ant-v2.pkl.\n",
      "(10000, 111)\n",
      "(0, 111)\n",
      "(0, 111)\n",
      "epochs 00 mse: 0.007\n",
      "epochs 01 mse: 0.005\n",
      "epochs 02 mse: 0.003\n",
      "epochs 03 mse: 0.002\n",
      "epochs 04 mse: 0.002\n",
      "epochs 05 mse: 0.001\n",
      "epochs 06 mse: 0.002\n",
      "epochs 07 mse: 0.002\n",
      "epochs 08 mse: 0.001\n",
      "epochs 09 mse: 0.002\n",
      "epochs 10 mse: 0.001\n",
      "epochs 11 mse: 0.001\n",
      "epochs 12 mse: 0.001\n",
      "epochs 13 mse: 0.001\n",
      "epochs 14 mse: 0.001\n",
      "epochs 15 mse: 0.001\n",
      "epochs 16 mse: 0.001\n",
      "epochs 17 mse: 0.001\n",
      "epochs 18 mse: 0.000\n",
      "epochs 19 mse: 0.001\n",
      "epochs 20 mse: 0.001\n",
      "epochs 21 mse: 0.001\n",
      "epochs 22 mse: 0.000\n",
      "epochs 23 mse: 0.000\n",
      "epochs 24 mse: 0.001\n",
      "epochs 25 mse: 0.000\n",
      "epochs 26 mse: 0.000\n",
      "epochs 27 mse: 0.000\n",
      "epochs 28 mse: 0.000\n",
      "epochs 29 mse: 0.000\n",
      "epochs 30 mse: 0.001\n",
      "epochs 31 mse: 0.000\n",
      "epochs 32 mse: 0.000\n",
      "epochs 33 mse: 0.000\n",
      "epochs 34 mse: 0.000\n",
      "epochs 35 mse: 0.000\n",
      "epochs 36 mse: 0.000\n",
      "epochs 37 mse: 0.000\n",
      "epochs 38 mse: 0.000\n",
      "epochs 39 mse: 0.000\n",
      "epochs 40 mse: 0.000\n",
      "epochs 41 mse: 0.000\n",
      "epochs 42 mse: 0.000\n",
      "epochs 43 mse: 0.000\n",
      "epochs 44 mse: 0.000\n",
      "epochs 45 mse: 0.000\n",
      "epochs 46 mse: 0.000\n",
      "epochs 47 mse: 0.000\n",
      "epochs 48 mse: 0.000\n",
      "epochs 49 mse: 0.000\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4608.861385931643, 4762.892613514793, 4875.497005639759, 4728.470999006117, 4777.461305700435, 5025.562480526303, 4739.479487313744, 4733.602866224793, 4905.255271273715, 4784.958037411946]\n",
      "mean return 4794.204145254325\n",
      "std of return 109.157627\n",
      "obs (1, 111) (1, 111)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4807.514380405739, 4805.592315054918, 2255.614401924408, 4673.042514319868, 4766.220074853176, 4831.5911208015905, 4887.676924504539, 4917.127836560739, 5013.397480502508, 4758.051838658916]\n",
      "mean return 4571.58288875864\n",
      "std of return 777.123133\n",
      "4794.204145254325 4571.58288875864\n",
      "109.15762657819188 777.1231328467775\n",
      "Training for expert_data/Ant-v2.pkl.\n",
      "(10000, 111)\n",
      "(0, 111)\n",
      "(0, 111)\n",
      "epochs 00 mse: 0.006\n",
      "epochs 01 mse: 0.004\n",
      "epochs 02 mse: 0.003\n",
      "epochs 03 mse: 0.003\n",
      "epochs 04 mse: 0.002\n",
      "epochs 05 mse: 0.002\n",
      "epochs 06 mse: 0.002\n",
      "epochs 07 mse: 0.001\n",
      "epochs 08 mse: 0.001\n",
      "epochs 09 mse: 0.001\n",
      "epochs 10 mse: 0.001\n",
      "epochs 11 mse: 0.001\n",
      "epochs 12 mse: 0.001\n",
      "epochs 13 mse: 0.001\n",
      "epochs 14 mse: 0.001\n",
      "epochs 15 mse: 0.001\n",
      "epochs 16 mse: 0.001\n",
      "epochs 17 mse: 0.001\n",
      "epochs 18 mse: 0.001\n",
      "epochs 19 mse: 0.001\n",
      "epochs 20 mse: 0.000\n",
      "epochs 21 mse: 0.001\n",
      "epochs 22 mse: 0.001\n",
      "epochs 23 mse: 0.000\n",
      "epochs 24 mse: 0.000\n",
      "epochs 25 mse: 0.000\n",
      "epochs 26 mse: 0.001\n",
      "epochs 27 mse: 0.000\n",
      "epochs 28 mse: 0.001\n",
      "epochs 29 mse: 0.000\n",
      "epochs 30 mse: 0.000\n",
      "epochs 31 mse: 0.000\n",
      "epochs 32 mse: 0.000\n",
      "epochs 33 mse: 0.000\n",
      "epochs 34 mse: 0.000\n",
      "epochs 35 mse: 0.000\n",
      "epochs 36 mse: 0.000\n",
      "epochs 37 mse: 0.000\n",
      "epochs 38 mse: 0.000\n",
      "epochs 39 mse: 0.000\n",
      "epochs 40 mse: 0.000\n",
      "epochs 41 mse: 0.000\n",
      "epochs 42 mse: 0.000\n",
      "epochs 43 mse: 0.000\n",
      "epochs 44 mse: 0.000\n",
      "epochs 45 mse: 0.000\n",
      "epochs 46 mse: 0.000\n",
      "epochs 47 mse: 0.000\n",
      "epochs 48 mse: 0.000\n",
      "epochs 49 mse: 0.000\n",
      "epochs 50 mse: 0.001\n",
      "epochs 51 mse: 0.000\n",
      "epochs 52 mse: 0.000\n",
      "epochs 53 mse: 0.000\n",
      "epochs 54 mse: 0.000\n",
      "epochs 55 mse: 0.000\n",
      "epochs 56 mse: 0.000\n",
      "epochs 57 mse: 0.000\n",
      "epochs 58 mse: 0.002\n",
      "epochs 59 mse: 0.000\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4938.823527635361, 4751.204769949038, 3271.3408828678466, 4696.148338397521, 4811.79665414039, 4737.636075316975, 4594.764851031927, 4740.049412832445, 4681.304338416201, 4672.704983829446]\n",
      "mean return 4589.577383441715\n",
      "std of return 447.939357\n",
      "obs (1, 111) (1, 111)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "test_run rollout 0\n",
      "test_run rollout 1\n",
      "test_run rollout 2\n",
      "test_run rollout 3\n",
      "test_run rollout 4\n",
      "test_run rollout 5\n",
      "test_run rollout 6\n",
      "test_run rollout 7\n",
      "test_run rollout 8\n",
      "test_run rollout 9\n",
      "returns [4709.500801737289, 4831.727953963016, 5010.308525502334, 4876.492572424646, 4866.839545130494, 4924.857265926433, 4924.998829914174, 4805.148501376519, 4604.833809884133, 4776.130202054485]\n",
      "mean return 4833.083800791353\n",
      "std of return 110.769971\n",
      "4589.577383441715 4833.083800791353\n",
      "447.9393569851269 110.7699706366639\n",
      "{0: (723.5586026220644, 4842.355160257128), 10: (3159.2197374406855, 4769.060049058062), 20: (4325.24092845146, 4852.47781265371), 30: (4702.600141355679, 4860.125324379065), 40: (4712.196266933692, 4762.455684482566), 50: (4794.204145254325, 4571.58288875864), 60: (4589.577383441715, 4833.083800791353)}\n"
     ]
    }
   ],
   "source": [
    "part2_3 = {}\n",
    "bc = []\n",
    "expert = []\n",
    "total_epochs = 70\n",
    "task = 'Ant-v2'\n",
    "for i in range(0, total_epochs, 10):\n",
    "    part2_3[i], _= train_model(task, i)\n",
    "    bc.append(part2_3[i][0])\n",
    "    expert.append(part2_3[i][1])\n",
    "\n",
    "print(part2_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[723.5586026220644,\n",
       " 3159.2197374406855,\n",
       " 4325.24092845146,\n",
       " 4702.600141355679,\n",
       " 4712.196266933692,\n",
       " 4794.204145254325,\n",
       " 4589.577383441715]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEdCAYAAAAb9oCRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nF9cb+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c3b5f4240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig = plt.figure()\n",
    "#plt.gcf().clear() \n",
    "x = np.arange(0, total_epochs, 10, dtype=int)\n",
    "#plt.plot(x, bc, 'r-')\n",
    "expert = np.repeat(expert[0], x.shape[0])\n",
    "plt.plot(x, bc, 'r-', label=\"bc\") \n",
    "plt.plot(x, expert, 'b--', label=\"expert\")\n",
    "plt.xlabel(\"# of Epochs\")\n",
    "plt.ylabel(\"Mean of Returns\")\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()\n",
    "#plt.plot(t, t, 'r--', t, t**2, 'bs', t, t**3, 'g^')\n",
    "#sns.tsplot ( time=xdata , data= , color =r , linestyle =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig(\"p2q3.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dagger \n",
    "def train_model_dagger(task, epochs, dagger_steps):\n",
    "    filename='expert_data/'+ task +'.pkl';\n",
    "    print(\"Training for {}.\".format(filename))\n",
    "    o, a = load_expert_data(filename)\n",
    "    a = a.reshape(a.shape[0], -1)\n",
    "    train_ratio = 1.0\n",
    "    valid_ratio = 0\n",
    "    test_ratio = 0 \n",
    "    train_index = int( train_ratio* o.shape[0])\n",
    "    valid_index = int( valid_ratio* o.shape[0]) + train_index\n",
    "\n",
    "    indices = np.random.permutation(o.shape[0])\n",
    "    train_indices, valid_indices, test_indices = indices[:train_index], indices[train_index:valid_index], indices[valid_index:]\n",
    "    o_train, o_valid, o_test = o[train_indices], o[valid_indices], o[test_indices]\n",
    "    a_train, a_valid, a_test = a[train_indices], a[valid_indices], a[test_indices]\n",
    "    print(o_train.shape)\n",
    "    print(o_valid.shape)\n",
    "    print(o_test.shape)\n",
    "    model_name = task +'ckpt'\n",
    "    \n",
    "    dagger_returns = []\n",
    "    \n",
    "    tf_reset()\n",
    "    with tf.Session() as sess:\n",
    "        input_ph, output_ph, output_pred = create_model(o_train, a_train)\n",
    "        \n",
    "        # create loss\n",
    "        mse = tf.reduce_mean(0.5 * tf.square(output_pred - output_ph))\n",
    "        # create optimizer\n",
    "        opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "\n",
    "        try:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, \"/tmp/1\"+model_name)\n",
    "        except ValueError:\n",
    "\n",
    "            # initialize variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # create saver to save model variables\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            # run training\n",
    "            batch_size = 64\n",
    "            iterations = o_train.shape[0] // batch_size\n",
    "            # run BC training\n",
    "            for epoch_step in range(epochs):\n",
    "                for training_step in range(iterations):\n",
    "                    #print(\"training step %d\" % training_step)\n",
    "                    # get a random subset of the training data\n",
    "                    indices = np.random.randint(low=0, high=o_train.shape[0], size=batch_size)\n",
    "                    input_batch = o_train[indices]\n",
    "                    output_batch = a_train[indices]\n",
    "\n",
    "                    # run the optimizer and get the mse\n",
    "                    _, mse_run = sess.run([opt, mse], feed_dict={input_ph: input_batch, output_ph: output_batch})\n",
    "\n",
    "                # print the mse every so often\n",
    "                print('epochs {0:02d} mse: {1:.3f}'.format(epoch_step, mse_run))\n",
    "                saver.save(sess, '/tmp/'+model_name)\n",
    "    \n",
    "        my_model = tf_util.function([input_ph], output_pred)\n",
    "        model_data = test_run(my_model, num_rollouts, task, expert_policy=False)\n",
    "        dagger_returns.append(model_data['returns'])\n",
    "        \n",
    "    for dagger_step in range(dagger_steps):\n",
    "        print(\"dagger step {}, o_train shape {}, a_train {}\\n\".format(dagger_step, o_train.shape, a_train.shape))\n",
    "        tf_reset()\n",
    "        with tf.Session() as sess:\n",
    "            input_ph, output_ph, output_pred = create_model(o_train, a_train)\n",
    "            # create loss\n",
    "            mse = tf.reduce_mean(0.5 * tf.square(output_pred - output_ph))\n",
    "            # create optimizer\n",
    "            opt = tf.train.AdamOptimizer().minimize(mse)       \n",
    "            # initialize variables\n",
    "            # sess.run(tf.global_variables_initializer())\n",
    "            # create saver to save model variables\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, \"/tmp/\"+model_name)\n",
    "            \n",
    "            # get a random subset of the training data\n",
    "            # run training\n",
    "            batch_size = 64\n",
    "            iterations = o_train.shape[0] // batch_size\n",
    "            # run BC training\n",
    "            for epoch_step in range(epochs):\n",
    "                for training_step in range(iterations):\n",
    "                    #print(\"training step %d\" % training_step)\n",
    "                    # get a random subset of the training data\n",
    "                    indices = np.random.randint(low=0, high=o_train.shape[0], size=batch_size)\n",
    "                    input_batch = o_train[indices]\n",
    "                    output_batch = a_train[indices]\n",
    "\n",
    "                    # run the optimizer and get the mse\n",
    "                    _, mse_run = sess.run([opt, mse], feed_dict={input_ph: input_batch, output_ph: output_batch})\n",
    "                \n",
    "                # print the mse every so often\n",
    "                #print('epochs {0:02d} mse: {1:.3f}'.format(epoch_step, mse_run))\n",
    "                saver.save(sess, '/tmp/'+model_name)\n",
    "                \n",
    "            # run model\n",
    "            my_model = tf_util.function([input_ph], output_pred)\n",
    "            model_data = test_run(my_model, num_rollouts, task, expert_policy=False)\n",
    "            dagger_returns.append(model_data['returns'])\n",
    "            \n",
    "            # get expert actions for observations\n",
    "            obs = model_data['observations']\n",
    "        tf_reset()\n",
    "        with tf.Session() as sess:\n",
    "            policy_fn = load_policy.load_policy('experts/'+task+'.pkl')\n",
    "            actions = policy_fn(obs)\n",
    "        actions = actions.reshape(actions.shape[0], -1)\n",
    "        o_train = np.concatenate((o_train, obs), axis=0)\n",
    "        a_train = np.concatenate((a_train, actions), axis=0)\n",
    "    \n",
    "    tf_reset()\n",
    "    with tf.Session() as sess:\n",
    "        policy_fn = load_policy.load_policy('experts/'+task+'.pkl')\n",
    "        ref_return = test_run(policy_fn, num_rollouts, task, expert_policy=True)\n",
    "\n",
    "#     model_mean, model_std = (np.mean(model_data['returns']), np.std(model_data['returns']))\n",
    "#     ref_mean, ref_std =  (np.mean(ref_data['returns']), np.std(ref_data['returns']))\n",
    "#     print(model_mean, ref_mean)\n",
    "#     print(model_std, ref_std)\n",
    "    return np.array(dagger_returns), ref_return['returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for expert_data/Humanoid-v2.pkl.\n",
      "(10000, 376)\n",
      "(0, 376)\n",
      "(0, 376)\n",
      "epochs 00 mse: 1.233\n",
      "epochs 01 mse: 0.864\n",
      "epochs 02 mse: 0.378\n",
      "epochs 03 mse: 0.666\n",
      "epochs 04 mse: 0.375\n",
      "epochs 05 mse: 0.406\n",
      "epochs 06 mse: 0.374\n",
      "epochs 07 mse: 0.630\n",
      "epochs 08 mse: 0.325\n",
      "epochs 09 mse: 0.324\n",
      "epochs 10 mse: 0.125\n",
      "epochs 11 mse: 0.154\n",
      "epochs 12 mse: 0.193\n",
      "epochs 13 mse: 0.717\n",
      "epochs 14 mse: 0.105\n",
      "epochs 15 mse: 0.309\n",
      "epochs 16 mse: 0.141\n",
      "epochs 17 mse: 0.111\n",
      "epochs 18 mse: 0.207\n",
      "epochs 19 mse: 0.073\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [404.9104830853798, 333.4333914436927, 352.2121321398815, 307.2988602603872, 449.31991033239433, 274.3083474623214, 518.9169783258521, 562.3365909139054, 511.92409063701757, 301.22532824899525]\n",
      "mean return 401.5886112849827\n",
      "std of return 98.140649\n",
      "dagger step 0, o_train shape (10000, 376), a_train (10000, 17)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/Humanoid-v2ckpt\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [467.51865019767536, 443.8442839192883, 326.3130174200725, 438.3329839658563, 702.4435606319731, 384.5469392549984, 383.5872791329942, 328.2565148350311, 357.5914251986426, 446.56096913144324]\n",
      "mean return 427.89956236879743\n",
      "std of return 103.290969\n",
      "obs (1, 376) (1, 376)\n",
      "dagger step 1, o_train shape (10838, 376), a_train (10838, 17)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/Humanoid-v2ckpt\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [336.48503178681864, 393.12646127789833, 411.6504643380279, 445.4870008703342, 461.81224865349685, 491.08842941196883, 337.819722818267, 296.0929495875779, 419.8177287683273, 358.60877308717215]\n",
      "mean return 395.19888105998893\n",
      "std of return 59.112252\n",
      "obs (1, 376) (1, 376)\n",
      "dagger step 2, o_train shape (11531, 376), a_train (11531, 17)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/Humanoid-v2ckpt\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [802.9566200841226, 618.8868978211897, 718.6441648281956, 648.7355098792723, 953.9094224961513, 626.7204067836395, 849.2574186941614, 360.1330821686138, 920.9518156728502, 426.39645924596056]\n",
      "mean return 692.6591797674157\n",
      "std of return 187.329115\n",
      "obs (1, 376) (1, 376)\n",
      "dagger step 3, o_train shape (12597, 376), a_train (12597, 17)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/Humanoid-v2ckpt\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [1036.8901097760993, 596.8413819379786, 958.447003382681, 1190.9069925924698, 1015.3550565690282, 858.7729888725517, 1070.377199034087, 945.7751490697364, 1024.7093012643265, 1146.7996344196308]\n",
      "mean return 984.4874816918589\n",
      "std of return 158.081724\n",
      "obs (1, 376) (1, 376)\n",
      "dagger step 4, o_train shape (13966, 376), a_train (13966, 17)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/Humanoid-v2ckpt\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [1436.7256061764717, 1111.163299910157, 1860.2605680644813, 2595.6055982963503, 729.4591927077479, 2488.24217747079, 1610.376257975529, 1604.3192357562955, 3363.374883321072, 1888.4985378671506]\n",
      "mean return 1868.8025357546048\n",
      "std of return 730.869486\n",
      "obs (1, 376) (1, 376)\n",
      "dagger step 5, o_train shape (16288, 376), a_train (16288, 17)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/Humanoid-v2ckpt\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [1398.6868102876929, 1287.5945862692731, 3268.7000405106955, 1972.8545916106489, 3907.3168069645617, 1459.12867937021, 2420.7755081690584, 3122.488679756194, 2524.6033670761726, 1972.1548112471396]\n",
      "mean return 2333.4303881261644\n",
      "std of return 837.322731\n",
      "obs (1, 376) (1, 376)\n",
      "dagger step 6, o_train shape (18986, 376), a_train (18986, 17)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/Humanoid-v2ckpt\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [2570.0337349476345, 2822.0382030980527, 3196.492103756669, 1220.063121283078, 10077.46786343206, 4576.503674271959, 10039.81155230249, 3414.9742358992594, 5879.5624028135335, 1267.8532883232888]\n",
      "mean return 4506.480018012802\n",
      "std of return 3071.282839\n",
      "obs (1, 376) (1, 376)\n",
      "dagger step 7, o_train shape (23789, 376), a_train (23789, 17)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/Humanoid-v2ckpt\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [534.6673427391809, 10123.836061499887, 4369.946599639063, 4513.48403510482, 10168.501469371224, 10272.753723348917, 9971.670833035598, 837.6634974676778, 10303.438838402413, 7575.785764106897]\n",
      "mean return 6867.174816471568\n",
      "std of return 3785.263134\n",
      "obs (1, 376) (1, 376)\n",
      "dagger step 8, o_train shape (30698, 376), a_train (30698, 17)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/Humanoid-v2ckpt\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [10112.687170373902, 10418.826043115405, 10153.454642283272, 10423.373660708743, 10241.852770788497, 10372.808920254192, 10106.114361408341, 10201.533722900818, 10290.110701120217, 10216.70326302546]\n",
      "mean return 10253.746525597884\n",
      "std of return 112.922150\n",
      "obs (1, 376) (1, 376)\n",
      "dagger step 9, o_train shape (40698, 376), a_train (40698, 17)\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/Humanoid-v2ckpt\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [10420.66702404645, 10386.7899243594, 10356.299261313163, 10408.381836912917, 2475.9383684779323, 10290.021292108226, 10339.748963797305, 10475.261463711748, 10501.039637641095, 8617.085563316461]\n",
      "mean return 9427.12333356847\n",
      "std of return 2377.789456\n",
      "obs (1, 376) (1, 376)\n",
      "obs (1, 376) (1, 376)\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "returns [10448.766157003547, 10380.278897059736, 10379.85147338612, 10288.322936714138, 10361.041899876833, 10456.002937614387, 10317.74933817836, 10398.341833493994, 10331.738238230126, 10479.605137598728]\n",
      "mean return 10384.169884915596\n",
      "std of return 59.630105\n",
      "[[404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]\n",
      " [404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]\n",
      " [404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]\n",
      " [404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]\n",
      " [404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]\n",
      " [404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]\n",
      " [404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]\n",
      " [404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]\n",
      " [404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]\n",
      " [404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]\n",
      " [404.91048309 333.43339144 352.21213214 307.29886026 449.31991033\n",
      "  274.30834746 518.91697833 562.33659091 511.92409064 301.22532825]]\n"
     ]
    }
   ],
   "source": [
    "task = 'Humanoid-v2'\n",
    "dagger_steps = 10\n",
    "dagger, ref_return = train_model_dagger(task, 20, dagger_steps)\n",
    "bc = np.tile(dagger[0], (dagger.shape[0],1))\n",
    "expert = np.tile(ref_return, (dagger.shape[0],1))\n",
    "print(bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 10)\n",
      "(11,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qijing.huang/anaconda3/lib/python3.6/site-packages/seaborn/timeseries.py:183: UserWarning: The tsplot function is deprecated and will be removed or replaced (in a substantially altered version) in a future release.\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/qijing.huang/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:1633: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n",
      "/Users/qijing.huang/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:518: UserWarning: You have mixed positional and keyword arguments, some input will be discarded.\n",
      "  warnings.warn(\"You have mixed positional and keyword \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEKCAYAAADenhiQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1834ade240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "x = np.arange(0, dagger_steps+1, 1, dtype=int)\n",
    "print(dagger.shape)\n",
    "print(x.shape)\n",
    "plt.gcf().clear() \n",
    "dagger_plot = sns.tsplot(time=x, data=np.transpose(dagger), color='r', linestyle='-')\n",
    "bc_plot = sns.tsplot(time=x, data=np.transpose(bc), color='b', linestyle='--')\n",
    "expert_plot = sns.tsplot(time=x, data=np.transpose(expert), color='g', linestyle='--')\n",
    "\n",
    "plt.legend([dagger_plot, bc_plot, expert_plot], labels=[\"dagger\", \"bc\", \"expert\"])\n",
    "\n",
    "plt.ylabel(\"Average Return\")\n",
    "plt.xlabel(\"Dagger Steps\")\n",
    "# Legend .\n",
    "# plt.legend(loc ='bottom left')\n",
    "\n",
    "plt.show( )\n",
    "fig.savefig(\"p3q3.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}